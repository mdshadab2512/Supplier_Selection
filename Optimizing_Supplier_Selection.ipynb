{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "<!-- Introduction -->\n",
        "<h2><b>Introduction</b></h2>\n",
        "\n",
        "<p>In procurement and supplier selection, organizations face the challenge of evaluating multiple vendors based on various criteria such as <b>price, delivery cost, bid price, and extra charges</b>. Choosing the right supplier is crucial for optimizing costs, ensuring quality, and maintaining operational efficiency. However, selecting the best vendor is a complex decision-making process that involves analyzing multiple factors simultaneously.</p>\n",
        "\n",
        "<p>To address this challenge, we leverage <b>machine learning techniques</b> to identify and assign <b>criteria weights</b> to key evaluation factors. By analyzing historical data, we can determine which factors contribute most to supplier selection and use these insights to make more objective and data-driven decisions.</p>\n",
        "\n",
        "<p>Our approach begins with <b>preprocessing and transforming</b> the dataset to address <b>data inconsistencies</b> and optimize <b>feature engineering</b>. Next, we develop <b>machine learning models</b> to analyze <b>feature importance</b>, allowing us to derive the weight of each criterion in the decision-making process.</p>\n",
        "\n",
        "<p>Once the criteria weights are determined, we proceed to <b>rank vendors</b> using <b>Multi-Criteria Decision Making (MCDM) techniques</b>. These techniques, including <b>TOPSIS, VIKOR and AHP</b>, help us evaluate suppliers by considering multiple weighted criteria, ensuring a fair and systematic ranking process.</p>\n",
        "\n",
        "<p>Through this comprehensive analysis, we provide <b>valuable insights</b> into supplier evaluation, enabling better procurement decisions based on <b>quantitative and objective methods</b>. This data-driven approach enhances transparency, efficiency, and effectiveness in vendor selection.</p>\n"
      ],
      "metadata": {
        "id": "y7J61iSy7wVg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<!-- Installing Required Libraries -->\n",
        "<h2><b>Installing Required Libraries</b></h2>\n",
        "<p>Before performing any analysis, we need to install the necessary libraries:</p>\n",
        "<ul>\n",
        "    <li><b><code>pandas</code></b>: Essential for data manipulation and analysis.</li>\n",
        "    <li><b><code>odfpy</code></b>: Required for handling OpenDocument Format (ODF) files.</li>\n",
        "    <li><b><code>scikit-learn</code></b>: For machine learning models and data preprocessing.</li>\n",
        "\n",
        "</ul>\n"
      ],
      "metadata": {
        "id": "tMTvkYGr74J2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pandas odfpy scikit-learn\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O133dLmB755Y",
        "outputId": "3afda847-df4a-425e-b5cf-e6ba3f72f67a",
        "collapsed": true
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: odfpy in /usr/local/lib/python3.11/dist-packages (1.4.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.1)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.11/dist-packages (from odfpy) (0.7.1)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.14.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<!-- Importing Dependencies -->\n",
        "<h2><b>Importing Dependencies</b></h2>\n",
        "<p>We now import the key libraries needed for data processing, modeling, and visualization:</p>\n",
        "<ul>\n",
        "    <li><b><code>pandas</code></b> and <b><code>numpy</code></b>: For handling structured data and numerical computations.</li>\n",
        "    <li><b><code>sklearn</code></b>: Provides tools for preprocessing, model training, and evaluation.</li>\n",
        "    <li><b><code>lightgbm</code></b>: A high-performance gradient boosting framework.</li>\n",
        "    <li><b><code>seaborn</code></b> and <b><code>matplotlib</code></b>: Useful for visualizing data trends.</li>\n",
        "    <li><b>Additional Libraries:</b> Depending on our specific needs, we may utilize other libraries for data processing, visualization, or modeling.</li>\n",
        "</ul>\n"
      ],
      "metadata": {
        "id": "VfAFqxGp8DmS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.impute import KNNImputer\n",
        "from sklearn.model_selection import cross_validate, GridSearchCV\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.ensemble import RandomForestRegressor, ExtraTreesRegressor, AdaBoostRegressor\n",
        "from sklearn.linear_model import Ridge\n",
        "from lightgbm import LGBMRegressor\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.linalg import eig\n",
        "from itertools import combinations"
      ],
      "metadata": {
        "id": "igQ5UUPK8A24"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<!-- Loading the Dataset -->\n",
        "<h2><b>Loading the Dataset</b></h2>\n",
        "<p>We load the <code>.ods</code> file into a pandas DataFrame, allowing us to manipulate and analyze the data efficiently.</p>\n"
      ],
      "metadata": {
        "id": "3-oUGuwF8Hlj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_excel('/content/supplier_data.ods', engine='odf')\n"
      ],
      "metadata": {
        "id": "fvLdbFcM8Kd6"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<!-- Renaming Columns for Consistency -->\n",
        "<h2><b>Renaming Columns for Consistency</b></h2>\n",
        "<p>To ensure clarity and uniformity, we correct any typos and inconsistencies in column names.</p>\n"
      ],
      "metadata": {
        "id": "dCsFHd979WKB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = data.rename(columns={\n",
        "    'technecal_acceptance': 'technical_acceptance',\n",
        "    'extra_charage': 'extra_charge',\n",
        "    'items_offred': 'items_offered',\n",
        "    'items_reqested': 'items_requested',\n",
        "    'delivery_t': 'delivery_time'\n",
        "})\n"
      ],
      "metadata": {
        "id": "fP9CsY_z9T_z"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h2><b>Removing Redundant and Irrelevant Columns</b></h2>\n",
        "<p>Some columns do not contribute to meaningful analysis and should be removed. Before dropping them, we check their unique values to confirm redundancy.</p>\n"
      ],
      "metadata": {
        "id": "QdjG3S1q9yrz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cols_to_remove = ['bidreceive', 'extra_cha2', 'warranty', 'matl_orig', 'disc_amt', 'order number', 'no_of_item', 'items_requested']\n",
        "redundant_cols = ['bidreceive', 'extra_cha2', 'warranty', 'matl_orig', 'disc_amt']\n",
        "\n",
        "result = {col: data[col].value_counts() for col in redundant_cols}\n",
        "\n",
        "print(\"\\nCounts of unique values:\\n\")\n",
        "for col, counts in result.items():\n",
        "    print(counts.to_string(index=True))\n",
        "    print()\n",
        "\n",
        "data.drop(columns=cols_to_remove, inplace=True)\n",
        "print(\"Specified columns have been removed.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KKszduYp9aS-",
        "outputId": "f0e5adba-3e94-4779-d9b8-43c6785ffd37",
        "collapsed": true
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Counts of unique values:\n",
            "\n",
            "bidreceive\n",
            "-   -    20347\n",
            "\n",
            "extra_cha2\n",
            "0    20347\n",
            "\n",
            "warranty\n",
            "1 YEAR    1\n",
            "\n",
            "matl_orig\n",
            "BULACAN         1\n",
            "BULACAN TEST    1\n",
            "\n",
            "disc_amt\n",
            "0.00      20346\n",
            "386.23        1\n",
            "\n",
            "Specified columns have been removed.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h2>Filtering Out Invalid Bids</h2>\n",
        "<p>Any rows where the <code>bid_price</code> is zero indicate invalid or incomplete bids and should be removed.</p>\n"
      ],
      "metadata": {
        "id": "kFNhjcHo9-Yt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = data[data['bid_price'] != 0]\n",
        "print(f\"Number of rows after removing zero bid prices: {data.shape[0]}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xZIo11TT-VBR",
        "outputId": "2bbbbca0-9df8-4806-e1ad-731fdd12b64e",
        "collapsed": true
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of rows after removing zero bid prices: 7915\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h2>Handling Corrupt and Missing Date Values</h2>\n",
        "<p>Certain date fields contain invalid entries, which we need to filter out before performing any date-based calculations.</p>\n"
      ],
      "metadata": {
        "id": "N4MZ5puF-d0q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data=data[data['offer_date']!='###############################################################################################################################################################################################################################################################']\n",
        "data=data[data['offer_date']!='  -   -']\n",
        "data=data[data['offervalid']!='###############################################################################################################################################################################################################################################################']\n",
        "data=data[data['offervalid']!='  -   -']"
      ],
      "metadata": {
        "id": "dX14QEts-Vd8"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h2>Standardizing Date Format</h2>\n",
        "<p>To maintain consistency, we reformat date columns into <code>dd/mm/yyyy</code> format and ensure chronological correctness.</p>\n"
      ],
      "metadata": {
        "id": "m_0KQLuN-nNA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data[['offer_date', 'offervalid']] = data[['offer_date', 'offervalid']].astype(str)\n",
        "\n",
        "data['offer_date'] = (\n",
        "    data['offer_date'].str.slice(8, 10) + '/' +\n",
        "    data['offer_date'].str.slice(5, 7) + '/' +\n",
        "    data['offer_date'].str.slice(0, 4)\n",
        ")\n",
        "\n",
        "data['offervalid'] = (\n",
        "    data['offervalid'].str.slice(8, 10) + '/' +\n",
        "    data['offervalid'].str.slice(5, 7) + '/' +\n",
        "    data['offervalid'].str.slice(0, 4)\n",
        ")\n",
        "\n",
        "data['offervalid'] = data.apply(\n",
        "    lambda row: row['offervalid'][:-4] + row['offer_date'][-4:], axis=1\n",
        ")\n"
      ],
      "metadata": {
        "id": "6yCjxqPO-XU4"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h2>Calculating Bid Validity Duration</h2>\n",
        "<p>We compute the number of days between <code>offer_date</code> and <code>offervalid</code> to create a new feature, <code>validity_days</code>, which indicates how long the bid remains valid.</p>\n"
      ],
      "metadata": {
        "id": "4qCyqzyg-uB5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "days_between = [\n",
        "    abs((int(offervalid.split('/')[2]) - int(offer_date.split('/')[2])) * 365 +\n",
        "        (int(offervalid.split('/')[1]) - int(offer_date.split('/')[1])) * 30 +\n",
        "        (int(offervalid.split('/')[0]) - int(offer_date.split('/')[0])))\n",
        "    for offer_date, offervalid in zip(data['offer_date'], data['offervalid'])\n",
        "]\n",
        "data['validity_days'] = days_between\n",
        "data.drop(columns=['offer_date','offervalid'],inplace=True)\n"
      ],
      "metadata": {
        "id": "RnHG7A00-ZYT"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<div>\n",
        "    <h2>Handling Zero USD Prices</h2>\n",
        "    <p>The output reveals that our dataset includes rows where <code>total_amount</code> has a valid value, but <code>usd_price</code> is zero. To resolve this:</p>\n",
        "    <ul>\n",
        "        <li>We computed the <b>conversion rate</b> for each currency to USD.</li>\n",
        "        <li>We applied this rate to convert <code>total_amount</code> into <code>usd_price</code> for rows where <code>usd_price</code> was initially zero.</li>\n",
        "    </ul>\n",
        "    <p>By standardizing all prices in USD, we enhance data consistency, ensuring more reliable vendor comparisons and accurate cost analysis.</p>\n",
        "</div>\n"
      ],
      "metadata": {
        "id": "_NG2dec7EaHz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "conversion_rates = (\n",
        "    data.dropna(subset=['usd_price'])\n",
        "    .groupby('currency', group_keys=False)\n",
        "    .apply(lambda x: x.iloc[0]['usd_price'] / x.iloc[0]['total_amount'], include_groups=False)\n",
        "    .to_dict()\n",
        ")\n",
        "\n",
        "\n",
        "missing_usd_price_condition = data['usd_price'] == 0\n",
        "\n",
        "data.loc[missing_usd_price_condition, 'usd_price'] = data.loc[\n",
        "    missing_usd_price_condition\n",
        "].apply(lambda row: row['total_amount'] * conversion_rates.get(row['currency'], 0), axis=1)\n",
        "\n",
        "data = data[data['usd_price'] != 0]\n"
      ],
      "metadata": {
        "id": "BK7UXgwYEWLN"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<div>\n",
        "    <h2>Transforming Categorical Columns</h2>\n",
        "    <p>\n",
        "        To make our data suitable for modeling, we must convert categorical columns into numerical representations.\n",
        "        Since machine learning models cannot process categorical data directly, we first analyze the number of unique\n",
        "        values in each categorical column before applying transformations.\n",
        "    </p>\n",
        "</div>\n"
      ],
      "metadata": {
        "id": "xVm8E9kuEZav"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "categorical_cols=['currency', 'delivery_place', 'technical_acceptance',\n",
        "                  'action', 'delivery_term', 'payment_term']\n",
        "\n",
        "result = {col: data[col].value_counts() for col in categorical_cols}\n",
        "print(\"Counts of unique values:\")\n",
        "for col, counts in result.items():\n",
        "    print(counts.to_string())\n",
        "    print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JcOBXtNkEXA0",
        "outputId": "93a10e10-38d3-48f4-adc0-87e29d0d5a35",
        "collapsed": true
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Counts of unique values:\n",
            "currency\n",
            "EUR    4544\n",
            "GBP    2262\n",
            "USD     681\n",
            "CAD      32\n",
            "LD       26\n",
            "CHF      17\n",
            "JPY      12\n",
            "SEK       5\n",
            "DKK       1\n",
            "\n",
            "delivery_place\n",
            "Libya    4245\n",
            "BREGA    1404\n",
            "\n",
            "technical_acceptance\n",
            "True     5729\n",
            "False    1853\n",
            "\n",
            "action\n",
            "F    6461\n",
            "P     800\n",
            "N      13\n",
            "D       7\n",
            "Q       5\n",
            "I       5\n",
            "\n",
            "delivery_term\n",
            "1    5361\n",
            "2     643\n",
            "b     371\n",
            "5     257\n",
            "3     121\n",
            "6     109\n",
            "c      94\n",
            "4      67\n",
            "f      52\n",
            "7      49\n",
            "9      32\n",
            "8      29\n",
            "d      11\n",
            "A       7\n",
            "e       7\n",
            "\n",
            "payment_term\n",
            "2    4722\n",
            "1    1211\n",
            "7     294\n",
            "a     282\n",
            "5     219\n",
            "8     165\n",
            "3     158\n",
            "9     153\n",
            "4      82\n",
            "6      74\n",
            "b      38\n",
            "d       1\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h2>Numerical Encoding for Categorical Columns</h2>\n",
        "<p>To make categorical features suitable for machine learning models, we applied numerical encoding based on domain-specific reasoning.</p>\n",
        "\n",
        "<h3>1. Currency Mapping</h3>\n",
        "<ul>\n",
        "    <li>Currencies with lower USD equivalents receive higher values.</li>\n",
        "    <li>Since our company operates in Libya, we prioritize currencies that reduce our USD expenses.</li>\n",
        "</ul>\n",
        "\n",
        "<h3>2. Delivery Place Mapping</h3>\n",
        "<ul>\n",
        "    <li>Mapped according to extra delivery charges.</li>\n",
        "    <li><strong>BREGA</strong> is assigned a higher value due to lower additional costs.</li>\n",
        "</ul>\n",
        "\n",
        "<h3>3. Action Mapping</h3>\n",
        "<ul>\n",
        "    <li>Encodes actions based on desirability:</li>\n",
        "    <li><strong>F (Fulfilled)</strong> → Higher value (positive outcome).</li>\n",
        "    <li><strong>D (Declined)</strong> → Lower value (negative outcome).</li>\n",
        "</ul>\n",
        "\n",
        "<h3>4. Technical Acceptance Mapping</h3>\n",
        "<ul>\n",
        "    <li><strong>Accepted (True)</strong> → <code>2.0</code></li>\n",
        "    <li><strong>Rejected (False)</strong> → <code>1.0</code></li>\n",
        "</ul>\n",
        "\n",
        "<p>This encoding ensures our models can interpret categorical variables effectively while maintaining business relevance.</p>\n"
      ],
      "metadata": {
        "id": "wFtCu6hO-7JC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "currency_mapping = {'EUR': 2.0, 'GBP': 1.0, 'USD': 4.0, 'CAD': 3.0, 'LD': 6.0, 'CHF': 5.0, 'JPY': 9.0, 'SEK': 8.0, 'DKK': 7.0}\n",
        "deliveryplace_mapping = {'Libya': 1.0, 'BREGA': 2.0}\n",
        "action_mapping = {'F': 6.0, 'P': 5.0, 'N': 2.0, 'D': 1.0, 'Q': 4.0, 'I': 3.0}\n",
        "\n",
        "data = data.copy()\n",
        "\n",
        "data['delivery_place'] = data['delivery_place'].map(deliveryplace_mapping)\n",
        "data['currency'] = data['currency'].map(currency_mapping)\n",
        "data['technical_acceptance'] = data['technical_acceptance'].map({True: 2.0, False: 1.0})\n",
        "data['action'] = data['action'].map(action_mapping)\n",
        "\n"
      ],
      "metadata": {
        "id": "evS36JiM-bGv"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<div>\n",
        "    <h2>Frequency Encoding for Categorical Columns</h2>\n",
        "    <p>For some categorical columns, like <strong>delivery_term</strong> and <strong>payment_term</strong>, we use frequency encoding. This means:</p>\n",
        "    <ul>\n",
        "        <li>Each category is replaced with its frequency (how often it appears in the dataset).</li>\n",
        "        <li>This approach assumes that more frequent categories are more important or relevant.</li>\n",
        "        <li>Frequency encoding is particularly useful when there’s no inherent order or hierarchy in the categories, allowing us to capture their prevalence in the data.</li>\n",
        "    </ul>\n",
        "</div>\n"
      ],
      "metadata": {
        "id": "eWnKQ-K1AOHf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = data.copy()\n",
        "\n",
        "data.loc[:, 'delivery_term'] = data['delivery_term'].astype(str)\n",
        "delivery_term_encoding = data['delivery_term'].value_counts(normalize=True)\n",
        "data.loc[:, 'delivery_term'] = data['delivery_term'].map(delivery_term_encoding)\n",
        "\n",
        "data.loc[:, 'payment_term'] = data['payment_term'].astype(str)\n",
        "payment_term_encoding = data['payment_term'].value_counts(normalize=True)\n",
        "data.loc[:, 'payment_term'] = data['payment_term'].map(payment_term_encoding)\n"
      ],
      "metadata": {
        "id": "hDK9D09m_JGL"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<div>\n",
        "    <h2>Handling Missing Values</h2>\n",
        "    <p>Missing values can disrupt our analysis and modeling. Here, we handle them dynamically:</p>\n",
        "    <ul>\n",
        "        <li>For each missing value, we calculate the average value for that vendor (<strong>vendor code</strong>).</li>\n",
        "        <li>If no data is available for the vendor, we mark the value as <code>NaN</code> and later remove those rows.</li>\n",
        "        <li>This approach ensures that missing values are filled in a way that reflects vendor-specific patterns, making the imputation more accurate and meaningful.</li>\n",
        "    </ul>\n",
        "</div>\n"
      ],
      "metadata": {
        "id": "OvSoGTzkAS1c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def impute_missing_values_dynamic(df, column, group_column='vendor code'):\n",
        "    vendor_avg = df.groupby(group_column)[column].mean().round().astype(float)\n",
        "    counts = df.groupby(group_column)[column].count()\n",
        "    sums = df.groupby(group_column)[column].sum()\n",
        "\n",
        "    def impute_value(row):\n",
        "        if pd.isnull(row[column]):\n",
        "            group = row[group_column]\n",
        "            if counts[group] == 0:\n",
        "                return 'nan'\n",
        "            avg = sums[group] / counts[group]\n",
        "            avg_rounded = float(round(avg))\n",
        "            counts[group] += 1\n",
        "            sums[group] += avg_rounded\n",
        "            return avg_rounded\n",
        "        return row[column]\n",
        "\n",
        "    df[column] = df.apply(impute_value, axis=1)\n",
        "    return df\n",
        "\n",
        "columns_to_impute = ['action', 'currency', 'delivery_place']\n",
        "for cols in columns_to_impute:\n",
        "    data = impute_missing_values_dynamic(data, cols)\n",
        "\n",
        "data = data[data['delivery_place'] != 'nan']\n",
        "data = data[data['action'] != 'nan']"
      ],
      "metadata": {
        "id": "lSPJr03H_Mgr"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<div>\n",
        "    <h2>Standardizing Monetary Values</h2>\n",
        "    <p>To ensure consistency, we convert all monetary values to USD:</p>\n",
        "    <ul>\n",
        "        <li>Using the previously calculated conversion rates, we transform <strong>extra_charge</strong> and <strong>bid_price</strong> into USD equivalents.</li>\n",
        "        <li>This standardization allows us to compare prices across different currencies directly.</li>\n",
        "        <li>This step is crucial for accurate cost analysis and vendor comparisons.</li>\n",
        "    </ul>\n",
        "</div>\n"
      ],
      "metadata": {
        "id": "4n-iC5ymAe7d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mapped_conversion_rates = {currency_mapping[key]: conversion_rates[key] for key in conversion_rates if key in currency_mapping}\n",
        "\n",
        "def apply_conversion_rate(row, column_name):\n",
        "    currency = row['currency']\n",
        "    if currency in mapped_conversion_rates:\n",
        "        conversion_rate = mapped_conversion_rates[currency]\n",
        "        return row[column_name] * conversion_rate\n",
        "    else:\n",
        "        return row[column_name]\n",
        "\n",
        "data['extra_charge_usd'] = data.apply(lambda row: apply_conversion_rate(row, 'extra_charge'), axis=1)\n",
        "data['bidprice_usd'] = data.apply(lambda row: apply_conversion_rate(row, 'bid_price'), axis=1)"
      ],
      "metadata": {
        "id": "eSbkJFEp_XDq"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<div>\n",
        "    <h2>K-Nearest Neighbors (KNN) Imputation</h2>\n",
        "    <p>For columns like <strong>delivery_term</strong> and <strong>payment_term</strong>, we use K-Nearest Neighbors (KNN) imputation:</p>\n",
        "    <ul>\n",
        "        <li>KNN imputation estimates missing values based on the values of the nearest neighbors in the dataset.</li>\n",
        "        <li>This method is particularly useful when the missing values are related to other features in the dataset.</li>\n",
        "        <li>By using KNN, we ensure that the imputed values are consistent with the overall patterns in the data.</li>\n",
        "    </ul>\n",
        "</div>\n"
      ],
      "metadata": {
        "id": "DiBgaqMOAgB3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "imputer_data = data[['delivery_term', 'payment_term']]\n",
        "imputer = KNNImputer(n_neighbors=5)\n",
        "imputed_data = imputer.fit_transform(imputer_data)\n",
        "\n",
        "data['delivery_term'] = imputed_data[:, 0]\n",
        "data['payment_term'] = imputed_data[:, 1]"
      ],
      "metadata": {
        "id": "por76ryw_ZyN"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<div>\n",
        "    <h2>Feature Engineering</h2>\n",
        "    <p>Feature engineering is where we create new features to improve our model’s performance:</p>\n",
        "    <ul>\n",
        "        <li><strong>usdprice_after_discount:</strong> The final price after applying the discount, which is our target variable.</li>\n",
        "        <li><strong>Per-item metrics:</strong> We calculate <em>bid_price_per_item</em>, <em>discount_per_item</em>, and <em>delivery_cost_per_item</em> to normalize costs based on the number of items.</li>\n",
        "        <li><strong>Validity periods:</strong> We convert <em>validity_days</em> into weeks and months for easier interpretation.</li>\n",
        "        <li><strong>Vendor statistics:</strong> We compute vendor-specific metrics like average bid price, standard deviation, and fulfillment rate to capture vendor performance.</li>\n",
        "    </ul>\n",
        "    <p>These new features provide richer insights and help the model better understand the relationships in the data.</p>\n",
        "</div>\n"
      ],
      "metadata": {
        "id": "R58wykAsApea"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Feature engineering\n",
        "data['usdprice_after_discount'] = data['usd_price'] * (1 - data['discount'] / 100)\n",
        "\n",
        "data['bid_price_per_item'] = data['bidprice_usd'] / data['items_offered'].replace(0, np.nan)\n",
        "data['discount_per_item'] = data['discount'] / data['items_offered'].replace(0, np.nan)\n",
        "data['delivery_cost_per_item'] = data['extra_charge_usd'] / data['items_offered'].replace(0, np.nan)\n",
        "\n",
        "data['bid_price_per_item'] = data['bid_price_per_item'].fillna(0)\n",
        "data['discount_per_item'] = data['discount_per_item'].fillna(0)\n",
        "data['delivery_cost_per_item'] = data['delivery_cost_per_item'].fillna(0)\n",
        "\n",
        "data['validity_weeks'] = data['validity_days'] / 7\n",
        "data['validity_months'] = data['validity_days'] / 30\n",
        "\n",
        "# Vendor-specific statistics\n",
        "vendor_stats = data.groupby('vendor code').agg({\n",
        "    'bidprice_usd': ['mean', 'std'],\n",
        "    'action': lambda x: (x == 'F').mean()\n",
        "}).reset_index()\n",
        "\n",
        "vendor_stats.columns = ['vendor code', 'avg_bid_price', 'std_bid_price', 'fulfillment_rate']\n",
        "data = data.merge(vendor_stats, on='vendor code', how='left')\n",
        "\n",
        "data['avg_bid_price'] = data['avg_bid_price'].fillna(data['bidprice_usd'].mean())\n",
        "data['std_bid_price'] = data['std_bid_price'].fillna(0)\n",
        "data['fulfillment_rate'] = data['fulfillment_rate'].fillna(0)"
      ],
      "metadata": {
        "id": "hmXPcfbH_f24"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The warnings module in Python helps control warning messages. Here, we use it to suppress unnecessary FutureWarnings and DeprecationWarnings, which indicate upcoming library changes but don't affect model correctness. This keeps the output clean and focused on meaningful results."
      ],
      "metadata": {
        "id": "kiGSzRMJWirX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
        "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n"
      ],
      "metadata": {
        "id": "FPt-0JXEVng7"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<div>\n",
        "    <h2>Model Training & Evaluation</h2>\n",
        "    <p>We train multiple regression models and evaluate their performance using cross-validation. Our process includes:</p>\n",
        "    <ul>\n",
        "        <li>Scaling features using <b>MinMaxScaler</b>.</li>\n",
        "        <li>Training models like RandomForest, ExtraTrees, AdaBoost, LGBM, and Ridge regression.</li>\n",
        "        <li>Computing mean absolute error (MAE) for both training and validation sets.</li>\n",
        "        <li>Deriving feature importances for models that support it.</li>\n",
        "    </ul>\n",
        "    <p>This approach ensures robust model selection while providing insights into feature relevance.</p> <h3>Scaling & Cross-Validation</h3>\n",
        "    <ul>\n",
        "        <li>Data is scaled using <b>MinMaxScaler</b> for consistency.</li>\n",
        "        <li><b>5-fold cross-validation</b> evaluates models based on:\n",
        "            <ul>\n",
        "                <li><b>Mean Absolute Error (MAE)</b> – measures training & validation performance.</li>\n",
        "                <li><b>Average Error per Row</b> – tracks error impact based on dataset size.</li>\n",
        "            </ul>\n",
        "        </li>\n",
        "    </ul> <h3>Feature Importance Analysis</h3>\n",
        "    <ul>\n",
        "        <li>Tree-based models provide <b>feature importances</b>.</li>\n",
        "        <li>Ridge Regression uses <b>absolute coefficients</b>.</li>\n",
        "        <li>Models without importance scores assume equal feature contributions.</li>\n",
        "        <li>Final rankings highlight key factors affecting price variations.</li>\n",
        "    </ul>\n",
        "</div>\n"
      ],
      "metadata": {
        "id": "0D-v92TXBIHt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = data.drop(['vendor code', 'usdprice_after_discount'], axis=1)\n",
        "y = data['usdprice_after_discount']\n",
        "\n",
        "n_rows = len(data)\n",
        "\n",
        "models = {\n",
        "    'RandomForest': RandomForestRegressor(max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=150, random_state=42),\n",
        "    'ExtraTrees': ExtraTreesRegressor(n_estimators=100, random_state=42),\n",
        "    'AdaBoostRegressor': AdaBoostRegressor(random_state=42),\n",
        "    'LGBMRegressor': LGBMRegressor(n_estimators=100, learning_rate=0.1, verbose=-1, random_state=42),\n",
        "    'Ridge': Ridge(alpha=1.0)\n",
        "}\n",
        "\n",
        "results = {}\n",
        "scalar = MinMaxScaler()\n",
        "feature_importances = {model_name: [] for model_name in models.keys()}\n",
        "\n",
        "for name, model in models.items():\n",
        "    pipeline = make_pipeline(scalar, model)\n",
        "    cv_results = cross_validate(pipeline, X, y, cv=5,\n",
        "                                scoring=['neg_mean_squared_error', 'neg_mean_absolute_error', 'r2'],\n",
        "                                return_train_score=True)\n",
        "\n",
        "    train_mae = -cv_results['train_neg_mean_absolute_error'].mean()\n",
        "    valid_mae = -cv_results['test_neg_mean_absolute_error'].mean()\n",
        "\n",
        "    results[name] = {\n",
        "        'train_mae': train_mae,\n",
        "        'valid_mae': valid_mae,\n",
        "        'train_avg_error_per_row': train_mae / n_rows,\n",
        "        'valid_avg_error_per_row': valid_mae / n_rows\n",
        "    }\n",
        "\n",
        "    print(f\"{name}\")\n",
        "    print(f\"MAE-train: {results[name]['train_mae']:.2f}\")\n",
        "    print(f\"MAE-valid: {results[name]['valid_mae']:.2f}\")\n",
        "    print(f\"Average Error per Row - train: {results[name]['train_avg_error_per_row']:.6f}\")\n",
        "    print(f\"Average Error per Row - valid: {results[name]['valid_avg_error_per_row']:.6f}\")\n",
        "    print()\n",
        "\n",
        "    pipeline.fit(X, y)\n",
        "\n",
        "    if hasattr(model, 'feature_importances_'):\n",
        "        importances = model.feature_importances_\n",
        "        importances_normalized = importances / np.sum(importances)\n",
        "        feature_importances[name] = importances_normalized\n",
        "\n",
        "        df_imp = pd.DataFrame({\n",
        "            'Feature': X.columns,\n",
        "            'Importance': importances_normalized\n",
        "        }).sort_values(by='Importance', ascending=False).reset_index(drop=True)\n",
        "    elif hasattr(model, 'coef_'):\n",
        "        importances = np.abs(model.coef_)\n",
        "        importances_normalized = importances / np.sum(importances)\n",
        "        feature_importances[name] = importances_normalized\n",
        "\n",
        "        df_imp = pd.DataFrame({\n",
        "            'Feature': X.columns,\n",
        "            'Importance': importances_normalized\n",
        "        }).sort_values(by='Importance', ascending=False).reset_index(drop=True)\n",
        "    else:\n",
        "        feature_importances[name] = [0] * len(X.columns)\n",
        "\n",
        "df_feature_importances = pd.DataFrame(feature_importances, index=X.columns)\n",
        "df_feature_importances = df_feature_importances.sort_values(by=list(models.keys()), ascending=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IosT2zue_7Z6",
        "outputId": "38542261-ae16-4f54-d184-811721d31b39",
        "collapsed": true
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RandomForest\n",
            "MAE-train: 4094.93\n",
            "MAE-valid: 11646.18\n",
            "Average Error per Row - train: 0.545119\n",
            "Average Error per Row - valid: 1.550344\n",
            "\n",
            "ExtraTrees\n",
            "MAE-train: 0.00\n",
            "MAE-valid: 4954.63\n",
            "Average Error per Row - train: 0.000000\n",
            "Average Error per Row - valid: 0.659562\n",
            "\n",
            "AdaBoostRegressor\n",
            "MAE-train: 17110.52\n",
            "MAE-valid: 23299.11\n",
            "Average Error per Row - train: 2.277759\n",
            "Average Error per Row - valid: 3.101585\n",
            "\n",
            "LGBMRegressor\n",
            "MAE-train: 26364.13\n",
            "MAE-valid: 29068.43\n",
            "Average Error per Row - train: 3.509602\n",
            "Average Error per Row - valid: 3.869599\n",
            "\n",
            "Ridge\n",
            "MAE-train: 28977.68\n",
            "MAE-valid: 31305.42\n",
            "Average Error per Row - train: 3.857519\n",
            "Average Error per Row - valid: 4.167388\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "By leveraging Machine Learning models, we obtain the feature importance values for each attribute. These values serve as the weights for our criteria, guiding the decision-making process.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "_a_F-3rMrQPw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_feature_importances.head(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "collapsed": true,
        "id": "3GmlJxALZPn1",
        "outputId": "c9c66aa7-cc0d-4f07-abae-2861521faa50"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                        RandomForest  ExtraTrees  AdaBoostRegressor  \\\n",
              "usd_price                   0.253876    0.301072           0.388517   \n",
              "delivery_cost_per_item      0.190413    0.043167           0.078709   \n",
              "bid_price                   0.156071    0.147506           0.091448   \n",
              "extra_charge_usd            0.131033    0.098517           0.006878   \n",
              "total_amount                0.090611    0.128473           0.069632   \n",
              "bidprice_usd                0.069796    0.248162           0.174744   \n",
              "bid_price_per_item          0.063871    0.018579           0.041601   \n",
              "extra_charge                0.039640    0.007495           0.144832   \n",
              "payment_term                0.000829    0.000698           0.000000   \n",
              "validity_months             0.000711    0.001264           0.001054   \n",
              "\n",
              "                        LGBMRegressor     Ridge  \n",
              "usd_price                    0.260000  0.212301  \n",
              "delivery_cost_per_item       0.090333  0.043471  \n",
              "bid_price                    0.071333  0.124427  \n",
              "extra_charge_usd             0.051333  0.122506  \n",
              "total_amount                 0.054333  0.120607  \n",
              "bidprice_usd                 0.058000  0.178541  \n",
              "bid_price_per_item           0.118333  0.087319  \n",
              "extra_charge                 0.096333  0.074261  \n",
              "payment_term                 0.018333  0.000102  \n",
              "validity_months              0.000000  0.000051  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-36b6f0c9-ee2a-464e-a325-2d17c389e9de\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>RandomForest</th>\n",
              "      <th>ExtraTrees</th>\n",
              "      <th>AdaBoostRegressor</th>\n",
              "      <th>LGBMRegressor</th>\n",
              "      <th>Ridge</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>usd_price</th>\n",
              "      <td>0.253876</td>\n",
              "      <td>0.301072</td>\n",
              "      <td>0.388517</td>\n",
              "      <td>0.260000</td>\n",
              "      <td>0.212301</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>delivery_cost_per_item</th>\n",
              "      <td>0.190413</td>\n",
              "      <td>0.043167</td>\n",
              "      <td>0.078709</td>\n",
              "      <td>0.090333</td>\n",
              "      <td>0.043471</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>bid_price</th>\n",
              "      <td>0.156071</td>\n",
              "      <td>0.147506</td>\n",
              "      <td>0.091448</td>\n",
              "      <td>0.071333</td>\n",
              "      <td>0.124427</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>extra_charge_usd</th>\n",
              "      <td>0.131033</td>\n",
              "      <td>0.098517</td>\n",
              "      <td>0.006878</td>\n",
              "      <td>0.051333</td>\n",
              "      <td>0.122506</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>total_amount</th>\n",
              "      <td>0.090611</td>\n",
              "      <td>0.128473</td>\n",
              "      <td>0.069632</td>\n",
              "      <td>0.054333</td>\n",
              "      <td>0.120607</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>bidprice_usd</th>\n",
              "      <td>0.069796</td>\n",
              "      <td>0.248162</td>\n",
              "      <td>0.174744</td>\n",
              "      <td>0.058000</td>\n",
              "      <td>0.178541</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>bid_price_per_item</th>\n",
              "      <td>0.063871</td>\n",
              "      <td>0.018579</td>\n",
              "      <td>0.041601</td>\n",
              "      <td>0.118333</td>\n",
              "      <td>0.087319</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>extra_charge</th>\n",
              "      <td>0.039640</td>\n",
              "      <td>0.007495</td>\n",
              "      <td>0.144832</td>\n",
              "      <td>0.096333</td>\n",
              "      <td>0.074261</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>payment_term</th>\n",
              "      <td>0.000829</td>\n",
              "      <td>0.000698</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.018333</td>\n",
              "      <td>0.000102</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>validity_months</th>\n",
              "      <td>0.000711</td>\n",
              "      <td>0.001264</td>\n",
              "      <td>0.001054</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000051</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-36b6f0c9-ee2a-464e-a325-2d17c389e9de')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-36b6f0c9-ee2a-464e-a325-2d17c389e9de button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-36b6f0c9-ee2a-464e-a325-2d17c389e9de');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-4b33c384-5de1-4308-a529-c8fe4f0067b8\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-4b33c384-5de1-4308-a529-c8fe4f0067b8')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-4b33c384-5de1-4308-a529-c8fe4f0067b8 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df_feature_importances",
              "summary": "{\n  \"name\": \"df_feature_importances\",\n  \"rows\": 25,\n  \"fields\": [\n    {\n      \"column\": \"RandomForest\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.07099686815434095,\n        \"min\": 0.0,\n        \"max\": 0.2538764602697406,\n        \"num_unique_values\": 25,\n        \"samples\": [\n          0.000829440616949542,\n          0.00019594006187342104,\n          0.2538764602697406\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ExtraTrees\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.08227714515365984,\n        \"min\": 0.0,\n        \"max\": 0.30107196323772645,\n        \"num_unique_values\": 25,\n        \"samples\": [\n          0.0006976971601112017,\n          0.0009810255009369247,\n          0.30107196323772645\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"AdaBoostRegressor\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.08747586408573577,\n        \"min\": 0.0,\n        \"max\": 0.3885174709072188,\n        \"num_unique_values\": 16,\n        \"samples\": [\n          0.3885174709072188,\n          0.07870891221071477,\n          0.17474368527846051\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"LGBMRegressor\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.05747487373723506,\n        \"min\": 0.0,\n        \"max\": 0.26,\n        \"num_unique_values\": 18,\n        \"samples\": [\n          0.26,\n          0.09033333333333333,\n          0.018333333333333333\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Ridge\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.06370252165260963,\n        \"min\": 0.0,\n        \"max\": 0.2123011702889741,\n        \"num_unique_values\": 25,\n        \"samples\": [\n          0.0001020295127884076,\n          5.086422754379445e-05,\n          0.2123011702889741\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h1>Multi-Criteria Decision Making (MCDM)</h1> <p> Now that we have determined the criteria weights using feature importance values, we can proceed with constructing the decision matrix for vendor evaluation. This involves selecting the most relevant features and normalizing them appropriately. </p> <p> Features that positively impact vendor selection are scaled within the range [0,1], while cost-related attributes are transformed to reflect their inverse relationship with desirability. These weighted and normalized criteria form the foundation for applying MCDM techniques to rank vendors effectively. </p>"
      ],
      "metadata": {
        "id": "K2tlIm1epqXE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def prepare_decision_matrix(data, df_feature_importances):\n",
        "    selected_features = df_feature_importances.loc[(df_feature_importances != 0).any(axis=1)].index.tolist()\n",
        "    decision_matrix = data[['vendor code'] + selected_features].copy()\n",
        "\n",
        "    benefit_criteria = ['usd_price', 'bid_price_per_item']\n",
        "    cost_criteria = ['delivery_cost_per_item', 'extra_charge_usd']\n",
        "\n",
        "    scaler = MinMaxScaler()\n",
        "    decision_matrix[benefit_criteria] = scaler.fit_transform(decision_matrix[benefit_criteria])\n",
        "    decision_matrix[cost_criteria] = 1 - scaler.fit_transform(decision_matrix[cost_criteria])\n",
        "\n",
        "    df_feature_importances[\"Average_Weight\"] = df_feature_importances.mean(axis=1)\n",
        "    weights = df_feature_importances[\"Average_Weight\"].to_dict()\n",
        "\n",
        "    for feature in selected_features:\n",
        "        decision_matrix[feature] *= weights[feature]\n",
        "\n",
        "    return decision_matrix, selected_features\n",
        "\n",
        "decision_matrix, selected_features = prepare_decision_matrix(data, df_feature_importances)\n"
      ],
      "metadata": {
        "id": "cj7vLKmZexkp"
      },
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h2>TOPSIS: Technique for Order Preference by Similarity to Ideal Solution</h2>\n",
        "\n",
        "<p>\n",
        "    TOPSIS is a widely used Multi-Criteria Decision Making (MCDM) method that evaluates and ranks alternatives\n",
        "    based on their relative distance from an ideal best and worst solution. It helps in making objective decisions\n",
        "    by considering both beneficial and non-beneficial criteria.\n",
        "</p>\n",
        "\n",
        "<h3>Methodology:</h3>\n",
        "<ul>\n",
        "    <li><b>Construct a Decision Matrix:</b> Each vendor's performance is recorded across multiple criteria.</li>\n",
        "    <li><b>Identify Ideal and Worst Solutions:</b> The best and worst values for each criterion are determined.</li>\n",
        "    <li><b>Calculate Distances:</b> The Euclidean distance of each alternative from the ideal best and worst solutions is computed.</li>\n",
        "    <li><b>Compute TOPSIS Score:</b> The score is derived as the ratio of distance from the worst solution to the total distance.</li>\n",
        "    <li><b>Rank Alternatives:</b> Vendors are ranked in descending order based on their TOPSIS scores.</li>\n",
        "</ul>\n",
        "\n",
        "<p>\n",
        "    A higher TOPSIS score indicates a vendor is closer to the ideal solution, making it a preferable choice.\n",
        "    This method ensures a balanced selection by considering both the best and worst-case scenarios in decision-making.\n",
        "</p>\n"
      ],
      "metadata": {
        "id": "fwpJ5yQzqJrx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def topsis(decision_matrix, selected_features):\n",
        "    matrix = decision_matrix[selected_features].values.astype(float)\n",
        "    ideal_best = np.max(matrix, axis=0)\n",
        "    ideal_worst = np.min(matrix, axis=0)\n",
        "    distance_best = np.linalg.norm(matrix - ideal_best, axis=1)\n",
        "    distance_worst = np.linalg.norm(matrix - ideal_worst, axis=1)\n",
        "    return distance_worst / (distance_best + distance_worst)\n",
        "\n",
        "decision_matrix['TOPSIS_Score'] = topsis(decision_matrix, selected_features)\n",
        "print(decision_matrix[['vendor code', 'TOPSIS_Score']]\n",
        "      .sort_values(by='TOPSIS_Score', ascending=False)\n",
        "      .head(10)\n",
        "      .to_string(index=False))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "dDuHJMI2e-WS",
        "outputId": "9dd715f4-5b2d-47d4-9c07-71db87cf3430"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " vendor code  TOPSIS_Score\n",
            "    103159.0      0.998760\n",
            "    101997.0      0.507537\n",
            "    101868.0      0.053586\n",
            "      3028.0      0.050175\n",
            "    700112.0      0.044341\n",
            "      3365.0      0.041179\n",
            "    302531.0      0.041070\n",
            "    302562.0      0.039873\n",
            "    700112.0      0.027401\n",
            "    302531.0      0.018667\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "<h2>VIKOR: Multi-Criteria Optimization and Compromise Ranking</h2>\n",
        "\n",
        "<p>\n",
        "    VIKOR is a powerful Multi-Criteria Decision Making (MCDM)\n",
        "    method designed to identify the best compromise solution among multiple alternatives. It is particularly useful\n",
        "    when decision-makers need to balance conflicting criteria.\n",
        "</p>\n",
        "\n",
        "<h3>Methodology:</h3>\n",
        "<ul>\n",
        "    <li><b>Determine Best and Worst Values:</b> Identify the best and worst performance for each criterion.</li>\n",
        "    <li><b>Compute Utility and Regret Measures:</b>\n",
        "        <ul>\n",
        "            <li><b>Si (Utility Measure):</b> Aggregates the deviations of an alternative from the best criterion values.</li>\n",
        "            <li><b>Ri (Regret Measure):</b> Captures the worst deviation among all criteria for a given alternative.</li>\n",
        "        </ul>\n",
        "    </li>\n",
        "    <li><b>Calculate the VIKOR Score:</b> A weighted sum of Si and Ri is used to determine the ranking.</li>\n",
        "    <li><b>Rank Alternatives:</b> Lower VIKOR scores indicate better alternatives that offer an optimal trade-off between competing criteria.</li>\n",
        "</ul>\n",
        "\n",
        "<p>\n",
        "    VIKOR is particularly effective in scenarios where a compromise solution is needed rather than a strict optimal solution.\n",
        "    It provides a balanced approach by considering both the best and worst performance levels in decision-making.\n",
        "</p>\n",
        "\n"
      ],
      "metadata": {
        "id": "6xjFAB2oq2n9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def vikor(decision_matrix, selected_features):\n",
        "    matrix = decision_matrix[selected_features].values\n",
        "    f_best = np.min(matrix, axis=0)\n",
        "    f_worst = np.max(matrix, axis=0)\n",
        "    Si = np.sum((matrix - f_best) / (f_worst - f_best), axis=1)\n",
        "    Ri = np.max((matrix - f_best) / (f_worst - f_best), axis=1)\n",
        "    S_best, S_worst = np.min(Si), np.max(Si)\n",
        "    R_best, R_worst = np.min(Ri), np.max(Ri)\n",
        "    return 0.5 * ((Si - S_best) / (S_worst - S_best)) + 0.5 * ((Ri - R_best) / (R_worst - R_best))\n",
        "\n",
        "decision_matrix['VIKOR_Score'] = vikor(decision_matrix, selected_features)\n",
        "print(decision_matrix[['vendor code', 'VIKOR_Score']].sort_values(by='VIKOR_Score', ascending=False).head(10).to_string(index=False))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "Wif-b99KfCux",
        "outputId": "4b62f8ac-a36a-41ba-fa58-c83f29ead447"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " vendor code VIKOR_Score\n",
            "    103159.0         1.0\n",
            "    103159.0    0.929756\n",
            "    302531.0    0.926874\n",
            "    302531.0    0.926639\n",
            "    101997.0    0.913073\n",
            "    103491.0    0.906661\n",
            "      6572.0    0.898836\n",
            "    102141.0    0.897866\n",
            "    103159.0    0.897586\n",
            "    190482.0    0.895941\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "<h2>Analytic Hierarchy Process (AHP)</h2>\n",
        "\n",
        "<p>\n",
        "    AHP is a decision-making method that ranks alternatives based on weighted criteria.\n",
        "    It uses pairwise comparisons to derive priority weights and ensures consistency in judgments.\n",
        "</p>\n",
        "\n",
        "<h3>Key Steps:</h3>\n",
        "<ul>\n",
        "    <li>Construct a pairwise comparison matrix.</li>\n",
        "    <li>Compute priority weights using eigenvalues.</li>\n",
        "    <li>Check consistency (CR &lt; 0.1 preferred).</li>\n",
        "    <li>Calculate and normalize AHP scores.</li>\n",
        "</ul>\n",
        "\n",
        "<p>\n",
        "    This method is useful for selecting the best vendor based on multiple attributes.\n",
        "</p>\n",
        "\n"
      ],
      "metadata": {
        "id": "OK-LsuZWrlU5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_pairwise_matrix(weights):\n",
        "    n = len(weights)\n",
        "    return np.array([[weights[i] / weights[j] if weights[j] != 0 else 1 for j in range(n)] for i in range(n)])\n",
        "\n",
        "def compute_priority_weights(pairwise_matrix):\n",
        "    eigenvalues, eigenvectors = eig(pairwise_matrix)\n",
        "    principal_eigenvector = eigenvectors[:, np.argmax(eigenvalues)].real\n",
        "    return principal_eigenvector / principal_eigenvector.sum()\n",
        "\n",
        "def check_consistency(pairwise_matrix, priority_weights):\n",
        "    n = len(priority_weights)\n",
        "    lambda_max = np.max(eig(pairwise_matrix)[0].real)\n",
        "    consistency_index = (lambda_max - n) / (n - 1) if n > 1 else 0\n",
        "    random_index = {1: 0.00, 2: 0.00, 3: 0.58, 4: 0.90, 5: 1.12, 6: 1.24, 7: 1.32,\n",
        "                    8: 1.41, 9: 1.45, 10: 1.49}.get(n, 1.49)\n",
        "    consistency_ratio = consistency_index / random_index if random_index else 0\n",
        "    if consistency_ratio > 0.1:\n",
        "        print(f\"⚠️ Warning: Consistency Ratio = {consistency_ratio:.3f} (> 0.1), weights may need adjustment!\")\n",
        "\n",
        "def calculate_ahp_scores(data, selected_features, priority_weights):\n",
        "    decision_matrix = data[['vendor code'] + selected_features].copy()\n",
        "    for feature, weight in zip(selected_features, priority_weights):\n",
        "        decision_matrix[feature] *= weight\n",
        "    decision_matrix['AHP_Score'] = decision_matrix[selected_features].sum(axis=1)\n",
        "    decision_matrix[\"AHP_Score_Normalized\"] = (\n",
        "        decision_matrix[\"AHP_Score\"] - decision_matrix[\"AHP_Score\"].min()\n",
        "    ) / (decision_matrix[\"AHP_Score\"].max() - decision_matrix[\"AHP_Score\"].min())\n",
        "    return decision_matrix[['vendor code', 'AHP_Score_Normalized']].sort_values(by=\"AHP_Score_Normalized\", ascending=False)\n",
        "\n",
        "def ahp_ranking(data, df_feature_importances):\n",
        "    selected_features = df_feature_importances[df_feature_importances.sum(axis=1) > 0].index.tolist()\n",
        "    weights = df_feature_importances.loc[selected_features].mean(axis=1).values\n",
        "    pairwise_matrix = compute_pairwise_matrix(weights)\n",
        "    priority_weights = compute_priority_weights(pairwise_matrix)\n",
        "    check_consistency(pairwise_matrix, priority_weights)\n",
        "    return calculate_ahp_scores(data, selected_features, priority_weights)\n",
        "\n",
        "ranked_vendors = ahp_ranking(data, df_feature_importances)\n",
        "print(ranked_vendors.head(10).to_string(index=False))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "UNo4ayxvdmtf",
        "outputId": "05c179e1-cf06-4e5a-f05d-481c63a7786c"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " vendor code AHP_Score_Normalized\n",
            "    103159.0                  1.0\n",
            "    101997.0             0.623734\n",
            "    302562.0             0.047029\n",
            "    302531.0             0.045608\n",
            "      3365.0             0.043022\n",
            "    101868.0             0.024576\n",
            "      3028.0             0.023486\n",
            "    302531.0             0.021301\n",
            "    302531.0             0.021106\n",
            "    700112.0             0.020814\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h1 style=\"text-align: center; font-size: 36px; color: #d9534f;\">Final Note</h1>\n",
        "\n",
        "<h1>Interpreting and Utilizing MCDM Scores</h1>\n",
        "\n",
        "<p>\n",
        "    Now that we have obtained the final scores from all Multi-Criteria Decision Making (MCDM) algorithms,\n",
        "    these rankings can be effectively used for decision-making. Each algorithm provides a different\n",
        "    perspective on vendor evaluation:\n",
        "</p>\n",
        "\n",
        "<ul>\n",
        "    <li><b>TOPSIS</b> ranks vendors based on their closeness to an ideal solution.</li>\n",
        "    <li><b>VIKOR</b> balances compromise solutions, highlighting trade-offs.</li>\n",
        "    <li><b>AHP</b> determines rankings based on a structured hierarchical weighting approach.</li>\n",
        "</ul>\n",
        "\n",
        "<p>\n",
        "    By analyzing these scores collectively, decision-makers can:\n",
        "</p>\n",
        "\n",
        "<ul>\n",
        "    <li>✔ Identify the top-performing vendors across multiple ranking techniques.</li>\n",
        "    <li>✔ Compare rankings from different algorithms to ensure robustness.</li>\n",
        "    <li>✔ Use the results to make informed procurement, partnership, or investment decisions.</li>\n",
        "</ul>\n",
        "\n",
        "<p>\n",
        "    In practical applications, the rankings can be integrated into dashboards,\n",
        "    automated procurement systems, or decision support tools to streamline\n",
        "    vendor selection and optimize resource allocation.\n",
        "</p>\n"
      ],
      "metadata": {
        "id": "kzpfweI6tJNl"
      }
    }
  ]
}